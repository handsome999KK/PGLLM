import json
import requests
import re
import numpy as np
import torch
from sklearn.neighbors import NearestNeighbors
import argparse
import sys
def read_matrices_from_file(file_path):
    with open(file_path, 'r') as file:
        content = file.read()

    matrices = []
    current_matrix = []
    in_matrix = False

    for line in content.split('\n'):
        line = line.strip()
        if line.startswith('[['):
            in_matrix = True
            current_matrix = [line[2:]]  
        elif line.endswith(']]'):
            in_matrix = False
            current_matrix.append(line[:-2]) 
            matrices.append(current_matrix)
            current_matrix = []
        elif in_matrix:
            current_matrix.append(line)

    matrix_arrays = []
    for matrix in matrices:
        matrix_str = ' '.join(matrix)
        matrix_str = matrix_str.replace('[', '').replace(']', '')
        matrix_data = np.fromstring(matrix_str, sep=' ')
        matrix_arrays.append(matrix_data)

    text_features = torch.tensor(np.vstack(matrix_arrays), dtype=torch.float32)
    return text_features





def main(args):
    with open(args.PointLLM_results_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    if args.dataset_split == "MN1":
        base_prompt = "Given a free-form description of a 3D object, please calculate the probability（0-100） that the content described in the following text pertains to any of the following categories. The description of this 3D object is generated by an LLM and may be inaccurate. In addition, I will provide you with descriptions of other 3D objects that share similar features with this object of this category. You need to take these similar 3D model descriptions into account as well. 0=no relation, 100=perfect match. \n\ncategories: airplane, bathtub, bed, bench, bookshelf, bottle, bowl, car, chair, cone, cup, curtain, desk."

    elif args.dataset_split == "MN2":
        base_prompt = "Given a free-form description of a 3D object, please calculate the probability（0-100） that the content described in the following text pertains to any of the following categories. The description of this 3D object is generated by an LLM and may be inaccurate. In addition, I will provide you with descriptions of other 3D objects that share similar features with this object of this category. You need to take these similar 3D model descriptions into account as well. 0=no relation, 100=perfect match. \n\ncategories: door, dresser, flower pot, glass box, guitar, keyboard, lamp, laptop, mantel, monitor, night stand, person, piano."

    elif args.dataset_split == "MN3":
        base_prompt = "Given a free-form description of a 3D object, please calculate the probability（0-100） that the content described in the following text pertains to any of the following categories. The description of this 3D object is generated by an LLM and may be inaccurate. In addition, I will provide you with descriptions of other 3D objects that share similar features with this object of this category. You need to take these similar 3D model descriptions into account as well. 0=no relation, 100=perfect match. \n\ncategories: plant, radio, range hood, sink, sofa, stairs, stool, table, tent, toilet, tv stand, vase, wardrobe, xbox."

    else:
        print(f"error dataset split choice")
        sys.exit(1)
    base = "Output ONLY a numerical score. Do not provide additional explanations."
    model_outputs = [item["model_output"] for item in data["results"]]

    API_KEY = ""
    API_ENDPOINT = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    file_path = args.features_path
    point_features = read_matrices_from_file(file_path)

    nbrs = NearestNeighbors(n_neighbors=4, metric='euclidean')
    nbrs.fit(point_features)

    distances, indices = nbrs.kneighbors(point_features)  

    knn_matrix = np.zeros((point_features.shape[0], point_features.shape[0]))

    rows = np.arange(point_features.shape[0]).repeat(3)  
    cols = indices[:, 1:4].reshape(-1) 
    vals = np.exp(-distances[:, 1:4].reshape(-1))  

    knn_matrix[rows, cols] = vals

    results = []

    for idx, output in enumerate(model_outputs):
        try:
            row_index = idx
            row = knn_matrix[row_index]
            top5_cols = np.argsort(row)[-3:][::-1] 

            PROMPT_LP2 = []
            first_item = True 

            for item in data["results"]:
                if item["object_id"] in top5_cols:
                    if first_item:
                        PROMPT_LP2.append(item["model_output"])
                        first_item = False
                    else:
                        PROMPT_LP2.append("\n" + item["model_output"])

            PROMPT_LP2 = "".join(PROMPT_LP2)

            PROMPT1 = "The description requiring probability calculation: " + output
            PROMPT2 = "Descriptions of 3D objects with similar features: " + PROMPT_LP2
            full_query = f"{base_prompt}\n\n{PROMPT1}\n\n{PROMPT2}\n\n{base}"
   
            payload = {
                "model": "deepseek-chat",  
                "messages": [{"role": "user", "content": full_query}],
                "temperature": 0.1,
                "max_tokens": 3  # 
            }

            response = requests.post(API_ENDPOINT, headers=headers, json=payload)
            response.raise_for_status()

            raw_content = response.json()["choices"][0]["message"]["content"].strip()

            match = re.search(r'\b(100|\d{1,2})\b', raw_content)
            if not match:
                raise ValueError(f"No valid score found in response: {raw_content}")

            score = int(match.group())

            if not 0 <= score <= 100:
                raise ValueError(f"Score out of range: {score}")

            results.append({
                "object_id": idx,
                "score": score,
                "raw_response": raw_content  
            })

        except Exception as e:
            print(f"Error processing object_id {idx}: {str(e)}")
            results.append({
                "object_id": idx,
                "score": None,
                "error": str(e),
                "raw_response": raw_content if 'raw_content' in locals() else None
            })

    with open(f'deepseek_results_OOD_{args.dataset_split}.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print("Processing completed. Results saved to deepseek_results_OOD.json")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()


    parser.add_argument("--features_path", type=str, required=True,
                        help="Path to the features JSON file")
    parser.add_argument("--PointLLM_results_path", type=str, required=True,
                        help="Path to PointLLM results")
    parser.add_argument("--dataset_split", type=str,
                        choices=["MN1", "MN2", "MN3"],
                        help="Name of the dataset to split")
    args = parser.parse_args()

    main(args)

